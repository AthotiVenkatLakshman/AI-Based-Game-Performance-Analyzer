{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "811bfcff-7eeb-422f-bd20-d2bc1a0a43cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deepface_env/lib/python3.9/site-packages/mtcnn/mtcnn.py:34: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "from insightface.app import FaceAnalysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6cf0580-194c-40a3-b177-9b1ce86f51c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/naniathoti/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/naniathoti/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/naniathoti/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/naniathoti/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/naniathoti/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "face_app = FaceAnalysis(name=\"buffalo_l\")\n",
    "face_app.prepare(ctx_id=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa2b9c51-0695-4e8a-87d2-be913393d817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'q' to quit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"âŒ Camera not accessible\")\n",
    "\n",
    "print(\"Press 'q' to quit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbdcc02b-e569-4089-805f-01c282a7b8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    \n",
    "    faces = face_app.get(frame)\n",
    "\n",
    "    for face in faces:\n",
    "        x1, y1, x2, y2 = map(int, face.bbox)\n",
    "\n",
    "       \n",
    "        face_img = frame[y1:y2, x1:x2]\n",
    "        if face_img.size == 0:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        age = int(face.age)\n",
    "        gender = \"Male\" if face.gender == 1 else \"Female\"\n",
    "\n",
    "        \n",
    "        try:\n",
    "            emotion_result = DeepFace.analyze(\n",
    "                face_img,\n",
    "                actions=[\"emotion\"],\n",
    "                enforce_detection=False,\n",
    "                silent=True\n",
    "            )\n",
    "\n",
    "            if isinstance(emotion_result, list):\n",
    "                emotion_result = emotion_result[0]\n",
    "\n",
    "            emotion = emotion_result[\"dominant_emotion\"]\n",
    "\n",
    "        except Exception:\n",
    "            emotion = \"Unknown\"\n",
    "\n",
    "        \n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        label = f\"Age: {age} | Gender: {gender} | Emotion: {emotion}\"\n",
    "\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            label,\n",
    "            (x1, y1 - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.6,\n",
    "            (0, 255, 0),\n",
    "            2\n",
    "        )\n",
    "\n",
    "    cv2.imshow(\"Live Face Analysis\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55a1bf4-adab-46cd-9441-64257fdc2be4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
